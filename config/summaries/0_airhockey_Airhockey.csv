Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
19000,0.09593747,1.4183332,599.0,-1.0000000894069672,-1.0000000894069672,1.0
20000,0.10283931,1.4183333,None,-1.0000000894069672,-1.0000000894069672,1.0
21000,0.08666557,1.4183332,None,None,None,1.0
22000,0.11560316,1.4183332,None,None,None,1.0
23000,0.08542918,1.4188703,None,None,None,1.0
24000,0.083772644,1.4198627,None,None,None,1.0
25000,0.07552605,1.4198627,None,None,None,1.0
26000,0.08655418,1.4198629,None,None,None,1.0
27000,0.083483666,1.4198627,None,None,None,1.0
28000,0.09014845,1.4198629,None,None,None,1.0
29000,0.08612944,1.4198627,None,None,None,1.0
30000,0.09346008,1.4198629,None,None,None,1.0
31000,0.091021925,1.4198627,None,None,None,1.0
32000,0.09320936,1.4198629,None,None,None,1.0
33000,0.09896085,1.4198627,None,None,None,1.0
34000,0.07428531,1.4199818,None,None,None,1.0
35000,0.060095396,1.4197733,None,None,None,1.0
36000,0.051991373,1.4197732,None,None,None,1.0
37000,0.05848424,1.4197733,None,None,None,1.0
38000,0.053620085,1.4197733,599.0,-1.0000000894069672,-1.0000000894069672,1.0
39000,0.055215277,1.4197732,None,-1.0000000894069672,-1.0000000894069672,1.0
40000,0.059275534,1.4197733,None,None,None,1.0
41000,0.054553933,1.4197733,None,None,None,1.0
42000,0.055387083,1.4197732,None,None,None,1.0
43000,0.05548706,1.4197733,None,None,None,1.0
44000,0.057383493,1.4197733,None,None,None,1.0
45000,0.039635032,1.4177864,None,None,None,1.0
46000,0.024880072,1.4170434,None,None,None,1.0
47000,0.023364041,1.4170436,None,None,None,1.0
48000,0.025539635,1.4170433,None,None,None,1.0
49000,0.024454866,1.4170436,None,None,None,1.0
50000,0.026160862,1.4170434,None,None,None,1.0
51000,0.027924303,1.4170436,None,None,None,1.0
52000,0.026821226,1.4170434,None,None,None,1.0
